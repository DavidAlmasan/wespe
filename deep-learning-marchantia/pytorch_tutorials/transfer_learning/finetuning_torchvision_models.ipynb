{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version:  0.4.1\n",
      "Torchvision Version:  0.2.1\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "print(\"PyTorch Version: \", torch.__version__)\n",
    "print(\"Torchvision Version: \", torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"./hymenoptera_data\"\n",
    "\n",
    "# Models to choose from [resnet, alexnet, vgg, squeezenet, densenet, inception]\n",
    "model_name = \"squeezenet\"\n",
    "\n",
    "# Number of classes in the dataset\n",
    "num_classes = 2\n",
    "\n",
    "# Batch size for training (change depending on memory)\n",
    "batch_size = 8\n",
    "\n",
    "# Number of epochs to train for\n",
    "num_epochs = 15\n",
    "\n",
    "# Flag for feature extracting. When False, we finetune the whole model,\n",
    "# when True we only update the reshaped layer params\n",
    "feature_extract = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25,\n",
    "               is_inception=False):\n",
    "    since = time.time()\n",
    "    \n",
    "    val_acc_history = []\n",
    "    \n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        \n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train() # Set model to training mode\n",
    "            else: \n",
    "                model.eval() # Set model to evaluate mode\n",
    "        \n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            \n",
    "            # Iterate over data\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # Get model outputs and calculate loss\n",
    "                    \n",
    "                    # Special case for inception because in training it has an auxiliary output.\n",
    "                    # In train mode we calculate the loss by summing the final output and the auxiliary output\n",
    "                    # but in testing we only consider the final output.\n",
    "                    if is_inception and phase == 'train':\n",
    "                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
    "                        outputs, aux_outputs = model(inputs)\n",
    "                        loss1 = criterion(outputs, labels)\n",
    "                        loss2 = criterion(aux_outputs, labels)\n",
    "                        loss = loss1 + 0.4*loss2\n",
    "                    else:\n",
    "                        outputs = model(inputs)\n",
    "                        loss = criterion(outputs,labels)\n",
    "                    \n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    \n",
    "                    # backward + optimize only if in trainig phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                \n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            \n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "            \n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "            \n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'val':\n",
    "                val_acc_history.append(epoch_acc)\n",
    "        \n",
    "        print()\n",
    "        \n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, val_acc_history\n",
    "            \n",
    "            \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/home/4thyr.oct2018/mtd38/marchantia-venv/lib/python3.5/site-packages/torchvision/models/squeezenet.py:94: UserWarning: nn.init.kaiming_uniform is now deprecated in favor of nn.init.kaiming_uniform_.\n",
      "  init.kaiming_uniform(m.weight.data)\n",
      "/var/home/4thyr.oct2018/mtd38/marchantia-venv/lib/python3.5/site-packages/torchvision/models/squeezenet.py:92: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n",
      "  init.normal(m.weight.data, mean=0.0, std=0.01)\n",
      "Downloading: \"https://download.pytorch.org/models/squeezenet1_0-a815701f.pth\" to /var/home/4thyr.oct2018/mtd38/.torch/models/squeezenet1_0-a815701f.pth\n",
      "100%|██████████| 5017600/5017600 [00:00<00:00, 982862.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SqueezeNet(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 96, kernel_size=(7, 7), stride=(2, 2))\n",
      "    (1): ReLU(inplace)\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "    (3): Fire(\n",
      "      (squeeze): Conv2d(96, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (squeeze_activation): ReLU(inplace)\n",
      "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand1x1_activation): ReLU(inplace)\n",
      "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (expand3x3_activation): ReLU(inplace)\n",
      "    )\n",
      "    (4): Fire(\n",
      "      (squeeze): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (squeeze_activation): ReLU(inplace)\n",
      "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand1x1_activation): ReLU(inplace)\n",
      "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (expand3x3_activation): ReLU(inplace)\n",
      "    )\n",
      "    (5): Fire(\n",
      "      (squeeze): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (squeeze_activation): ReLU(inplace)\n",
      "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand1x1_activation): ReLU(inplace)\n",
      "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (expand3x3_activation): ReLU(inplace)\n",
      "    )\n",
      "    (6): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "    (7): Fire(\n",
      "      (squeeze): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (squeeze_activation): ReLU(inplace)\n",
      "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand1x1_activation): ReLU(inplace)\n",
      "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (expand3x3_activation): ReLU(inplace)\n",
      "    )\n",
      "    (8): Fire(\n",
      "      (squeeze): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (squeeze_activation): ReLU(inplace)\n",
      "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand1x1_activation): ReLU(inplace)\n",
      "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (expand3x3_activation): ReLU(inplace)\n",
      "    )\n",
      "    (9): Fire(\n",
      "      (squeeze): Conv2d(384, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (squeeze_activation): ReLU(inplace)\n",
      "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand1x1_activation): ReLU(inplace)\n",
      "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (expand3x3_activation): ReLU(inplace)\n",
      "    )\n",
      "    (10): Fire(\n",
      "      (squeeze): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (squeeze_activation): ReLU(inplace)\n",
      "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand1x1_activation): ReLU(inplace)\n",
      "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (expand3x3_activation): ReLU(inplace)\n",
      "    )\n",
      "    (11): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "    (12): Fire(\n",
      "      (squeeze): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (squeeze_activation): ReLU(inplace)\n",
      "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand1x1_activation): ReLU(inplace)\n",
      "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (expand3x3_activation): ReLU(inplace)\n",
      "    )\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.5)\n",
      "    (1): Conv2d(512, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (2): ReLU(inplace)\n",
      "    (3): AvgPool2d(kernel_size=13, stride=1, padding=0)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def initialize_model(model_name, num_classes, feature_extract,\n",
    "                    use_pretrained=True):\n",
    "    model_ft = None\n",
    "    input_size = 0\n",
    "    \n",
    "    if model_name == \"resnet\":\n",
    "        \"\"\"Resnet18\n",
    "        \"\"\"\n",
    "        model_ft = models.resnet18(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes) # Overriding last layer\n",
    "        input_size = 224\n",
    "        \n",
    "    elif model_name == \"alexnet\":\n",
    "        \"\"\" Alexnet\n",
    "        \"\"\"\n",
    "        model_ft = models.alexnet(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "    \n",
    "    elif model_name == \"vgg\":\n",
    "        \"\"\" VGG11_bn\n",
    "        \"\"\"\n",
    "        model_ft = models.vgg11_bn(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "    \n",
    "    elif model_name == \"squeezenet\":\n",
    "        \"\"\" Squeezenet\n",
    "        \"\"\"\n",
    "        model_ft = models.squeezenet1_0(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n",
    "        model_ft.num_classes = num_classes\n",
    "        input_size = 224\n",
    "    \n",
    "    elif model_name == \"densenet\":\n",
    "        \"\"\" Densenet\n",
    "        \"\"\"\n",
    "        model_ft = models.densenet121(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier.in_features\n",
    "        model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "    \n",
    "    elif model_name == \"inception\":\n",
    "        \"\"\" Inception v3\n",
    "        Be careful, expects (299,299) sized images and has auxiliary output\n",
    "        \"\"\"\n",
    "        model_ft = models.inception_v3(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        # Handle the auxilary net\n",
    "        num_ftrs = model_ft.AuxLogits.fc.in_features\n",
    "        model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        # Handle the primary net\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 299\n",
    "    \n",
    "    else:\n",
    "        print(\"Invalid model name, exiting...\")\n",
    "        exit()\n",
    "\n",
    "    return model_ft, input_size\n",
    "\n",
    "# Initialize the model for this run\n",
    "model_ft, input_size = initialize_model(model_name, num_classes, feature_extract,\n",
    "                                      use_pretrained=True)\n",
    "\n",
    "# Print the model we just instantiated\n",
    "print(model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Datasets and Dataloaders...\n"
     ]
    }
   ],
   "source": [
    "# Loading the data\n",
    "\n",
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(input_size),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(input_size),\n",
    "        transforms.CenterCrop(input_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "print(\"Initializing Datasets and Dataloaders...\")\n",
    "\n",
    "# Create training and validation datasets\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']}\n",
    "# Create training and validation dataloaders\n",
    "dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], \n",
    "                                                   batch_size=batch_size, \n",
    "                                                   shuffle=True, \n",
    "                                                   num_workers=4) \n",
    "                    for x in ['train', 'val']}\n",
    "\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\t classifier.1.weight\n",
      "\t classifier.1.bias\n"
     ]
    }
   ],
   "source": [
    "# Creating the optimizer\n",
    "\n",
    "# Send the model to GPU\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "# Gather the parameters to be optimized/updated in this run.\n",
    "# If finetuning, update all parameters.\n",
    "# If feature extracting, only update parameters that we have just initalized\n",
    "# i.e. the parameters with requires_grad == True\n",
    "params_to_update = model_ft.parameters()\n",
    "print(\"Params to learn:\")\n",
    "if feature_extract:\n",
    "    params_to_update = []\n",
    "    for name, param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            print(\"\\t\", name)\n",
    "else:\n",
    "    for name, param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            print(\"\\t\", name)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/14\n",
      "----------\n",
      "train Loss: 0.2689 Acc: 0.8934\n",
      "val Loss: 0.3842 Acc: 0.8627\n",
      "\n",
      "Epoch 1/14\n",
      "----------\n",
      "train Loss: 0.2203 Acc: 0.8975\n",
      "val Loss: 0.3533 Acc: 0.9150\n",
      "\n",
      "Epoch 2/14\n",
      "----------\n",
      "train Loss: 0.2012 Acc: 0.9180\n",
      "val Loss: 0.3747 Acc: 0.9150\n",
      "\n",
      "Epoch 3/14\n",
      "----------\n",
      "train Loss: 0.1839 Acc: 0.9344\n",
      "val Loss: 0.3814 Acc: 0.9020\n",
      "\n",
      "Epoch 4/14\n",
      "----------\n",
      "train Loss: 0.1385 Acc: 0.9508\n",
      "val Loss: 0.3654 Acc: 0.9216\n",
      "\n",
      "Epoch 5/14\n",
      "----------\n",
      "train Loss: 0.1769 Acc: 0.9426\n",
      "val Loss: 0.3650 Acc: 0.9150\n",
      "\n",
      "Epoch 6/14\n",
      "----------\n",
      "train Loss: 0.1859 Acc: 0.9221\n",
      "val Loss: 0.3686 Acc: 0.8954\n",
      "\n",
      "Epoch 7/14\n",
      "----------\n",
      "train Loss: 0.1789 Acc: 0.9262\n",
      "val Loss: 0.3570 Acc: 0.9150\n",
      "\n",
      "Epoch 8/14\n",
      "----------\n",
      "train Loss: 0.1392 Acc: 0.9426\n",
      "val Loss: 0.3601 Acc: 0.9216\n",
      "\n",
      "Epoch 9/14\n",
      "----------\n",
      "train Loss: 0.1145 Acc: 0.9590\n",
      "val Loss: 0.3801 Acc: 0.9216\n",
      "\n",
      "Epoch 10/14\n",
      "----------\n",
      "train Loss: 0.1506 Acc: 0.9221\n",
      "val Loss: 0.3946 Acc: 0.9085\n",
      "\n",
      "Epoch 11/14\n",
      "----------\n",
      "train Loss: 0.1560 Acc: 0.9344\n",
      "val Loss: 0.3621 Acc: 0.9216\n",
      "\n",
      "Epoch 12/14\n",
      "----------\n",
      "train Loss: 0.1326 Acc: 0.9385\n",
      "val Loss: 0.3428 Acc: 0.9150\n",
      "\n",
      "Epoch 13/14\n",
      "----------\n",
      "train Loss: 0.1136 Acc: 0.9467\n",
      "val Loss: 0.3792 Acc: 0.9085\n",
      "\n",
      "Epoch 14/14\n",
      "----------\n",
      "train Loss: 0.1371 Acc: 0.9385\n",
      "val Loss: 0.3786 Acc: 0.9150\n",
      "\n",
      "Training complete in 0m 32s\n",
      "Best val Acc: 0.921569\n"
     ]
    }
   ],
   "source": [
    "# Setup the loss fn\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Train and evaluate\n",
    "model_ft, hist = train_model(model_ft, dataloaders_dict, criterion, optimizer_ft,\n",
    "                            num_epochs=num_epochs, is_inception=(model_name == \"inception\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/14\n",
      "----------\n",
      "train Loss: 0.7044 Acc: 0.4713\n",
      "val Loss: 0.6931 Acc: 0.4575\n",
      "\n",
      "Epoch 1/14\n",
      "----------\n",
      "train Loss: 0.6931 Acc: 0.5041\n",
      "val Loss: 0.6931 Acc: 0.4575\n",
      "\n",
      "Epoch 2/14\n",
      "----------\n",
      "train Loss: 0.6931 Acc: 0.5041\n",
      "val Loss: 0.6931 Acc: 0.4575\n",
      "\n",
      "Epoch 3/14\n",
      "----------\n",
      "train Loss: 0.6931 Acc: 0.5041\n",
      "val Loss: 0.6931 Acc: 0.4575\n",
      "\n",
      "Epoch 4/14\n",
      "----------\n",
      "train Loss: 0.6931 Acc: 0.5041\n",
      "val Loss: 0.6931 Acc: 0.4575\n",
      "\n",
      "Epoch 5/14\n",
      "----------\n",
      "train Loss: 0.6931 Acc: 0.5041\n",
      "val Loss: 0.6931 Acc: 0.4575\n",
      "\n",
      "Epoch 6/14\n",
      "----------\n",
      "train Loss: 0.6931 Acc: 0.5041\n",
      "val Loss: 0.6931 Acc: 0.4575\n",
      "\n",
      "Epoch 7/14\n",
      "----------\n",
      "train Loss: 0.6931 Acc: 0.5041\n",
      "val Loss: 0.6931 Acc: 0.4575\n",
      "\n",
      "Epoch 8/14\n",
      "----------\n",
      "train Loss: 0.6931 Acc: 0.5041\n",
      "val Loss: 0.6931 Acc: 0.4575\n",
      "\n",
      "Epoch 9/14\n",
      "----------\n",
      "train Loss: 0.6931 Acc: 0.5041\n",
      "val Loss: 0.6931 Acc: 0.4575\n",
      "\n",
      "Epoch 10/14\n",
      "----------\n",
      "train Loss: 0.6931 Acc: 0.5041\n",
      "val Loss: 0.6931 Acc: 0.4575\n",
      "\n",
      "Epoch 11/14\n",
      "----------\n",
      "train Loss: 0.6931 Acc: 0.5041\n",
      "val Loss: 0.6931 Acc: 0.4575\n",
      "\n",
      "Epoch 12/14\n",
      "----------\n",
      "train Loss: 0.6931 Acc: 0.5041\n",
      "val Loss: 0.6931 Acc: 0.4575\n",
      "\n",
      "Epoch 13/14\n",
      "----------\n",
      "train Loss: 0.6931 Acc: 0.5041\n",
      "val Loss: 0.6931 Acc: 0.4575\n",
      "\n",
      "Epoch 14/14\n",
      "----------\n",
      "train Loss: 0.6931 Acc: 0.5041\n",
      "val Loss: 0.6931 Acc: 0.4575\n",
      "\n",
      "Training complete in 0m 31s\n",
      "Best val Acc: 0.457516\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Comparison with model trained from scratch\n",
    "\n",
    "# Initialize the non-pretrained version of the model used for this run\n",
    "scratch_model, _ = initialize_model(model_name, num_classes,\n",
    "                                   feature_extract=False,\n",
    "                                   use_pretrained=False)\n",
    "scratch_model = scratch_model.to(device)\n",
    "scratch_optimizer = optim.SGD(scratch_model.parameters(), lr=0.001, momentum=0.9)\n",
    "scratch_criterion = nn.CrossEntropyLoss()\n",
    "_,scratch_hist = train_model(scratch_model, \n",
    "                             dataloaders_dict, \n",
    "                             scratch_criterion, \n",
    "                             scratch_optimizer, \n",
    "                             num_epochs=num_epochs, \n",
    "                             is_inception=(model_name==\"inception\"))\n",
    "\n",
    "# Plot the training curves of validation accuracy vs. number\n",
    "#  of training epochs for the transfer learning method and\n",
    "#  the model trained from scratch\n",
    "ohist = []\n",
    "shist = []\n",
    "\n",
    "ohist = [h.cpu().numpy() for h in hist]\n",
    "shist = [h.cpu().numpy() for h in scratch_hist]\n",
    "\n",
    "plt.title(\"Validation Accuracy vs. Number of Training Epochs\")\n",
    "plt.xlabel(\"Training Epochs\")\n",
    "plt.ylabel(\"Validation Accuracy\")\n",
    "plt.plot(range(1,num_epochs+1),ohist,label=\"Pretrained\")\n",
    "plt.plot(range(1,num_epochs+1),shist,label=\"Scratch\")\n",
    "plt.ylim((0,1.))\n",
    "plt.xticks(np.arange(1, num_epochs+1, 1.0))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
